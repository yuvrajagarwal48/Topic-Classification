{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YHTjfIyf_a7m"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-13 20:35:26.427100: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-02-13 20:35:26.685449: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-02-13 20:35:26.687742: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-13 20:35:27.783298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/lib/python3/dist-packages/paramiko/transport.py:220: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
            "  \"class\": algorithms.Blowfish,\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import preprocessing as kprocessing\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import re\n",
        "import nltk\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "udxuYHBo_ipM"
      },
      "outputs": [],
      "source": [
        "file_path='/content/drive/MyDrive/Colab Notebooks/Topic_summarization_data'\n",
        "epoch=10\n",
        "batch_size=128\n",
        "nr_categories=4\n",
        "class_names=['World', 'Sports', 'Business', 'Sci/Tech']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P_WVAR6D_iwD"
      },
      "outputs": [],
      "source": [
        "train_df=pd.read_csv('train.csv')\n",
        "test_df=pd.read_csv('test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "O9L8MSZG_iy1"
      },
      "outputs": [],
      "source": [
        "X_train=train_df['text']\n",
        "X_test=test_df['text']\n",
        "y_train_class=train_df['label']\n",
        "y_test_class=test_df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PEvxUpXA_i1i"
      },
      "outputs": [],
      "source": [
        "lab = LabelBinarizer()\n",
        "lab.fit(y_train_class)\n",
        "y_train = lab.transform(y_train_class)\n",
        "y_test=lab.transform(y_test_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWDR1-eO_i3f",
        "outputId": "b6958466-bc6c-4efa-a586-b996a07fe7bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_train: [[0 0 0 1]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]\n",
            " ...\n",
            " [1 0 0 0]\n",
            " [0 1 0 0]\n",
            " [0 0 1 0]]\n",
            "y_test: [[0 1 0 0]\n",
            " [1 0 0 0]\n",
            " [0 0 0 1]\n",
            " ...\n",
            " [0 0 0 1]\n",
            " [0 0 1 0]\n",
            " [0 1 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(\"y_train:\",y_train)\n",
        "print(\"y_test:\",y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noqQqUbk_i6C",
        "outputId": "37f161e2-537b-4d95-9d81-48b19489dba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coding of labels into a one-hot vector: 1 is [0 1 0 0]\n"
          ]
        }
      ],
      "source": [
        "n=101\n",
        "print(f'Coding of labels into a one-hot vector: {y_train_class[n]} is {y_train[n]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "pk46h8RF_8k_"
      },
      "outputs": [],
      "source": [
        "corpus = X_train\n",
        "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', oov_token=\"<pad>\", filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "voc = tokenizer.word_index\n",
        "reverse_voc = dict([(value, key) for (key, value) in voc.items()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_words=len(voc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "q6mQZAEb_8n6"
      },
      "outputs": [],
      "source": [
        "max_len = 200\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "X_train_seq = kprocessing.sequence.pad_sequences(sequences, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "W-xAZASN_8q7"
      },
      "outputs": [],
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test_seq = kprocessing.sequence.pad_sequences(sequences_test, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF-9QwaWACUQ",
        "outputId": "65b2f86a-a2f0-4b67-ba56-e500ebd06938"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,   51,  304, 3159],\n",
              "       [   0,    0,    0, ..., 2561,  565,   57],\n",
              "       [   0,    0,    0, ...,   96,   80,   42],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 2964, 2038, 1542],\n",
              "       [   0,    0,    0, ..., 2681, 1832,  564],\n",
              "       [   0,    0,    0, ...,   11,  633,  427]], dtype=int32)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8eOHQJzACXL",
        "outputId": "3349c5a7-a71f-408e-ccc4-a4c8b2e5b41d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,  650,  495,   58],\n",
              "       [   0,    0,    0, ...,  465,  188,   43],\n",
              "       [   0,    0,    0, ...,   82, 1020,   92],\n",
              "       ...,\n",
              "       [   0,    0,    0, ..., 6154,  282, 1854],\n",
              "       [   0,    0,    0, ...,  768, 2968,   73],\n",
              "       [   0,    0,    0, ..., 7053, 6973,  760]], dtype=int32)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSp1Hf9m_i82",
        "outputId": "a82cf6f5-a356-4cff-ee35-e28aaccb121d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape:  (120000, 200)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Example:  [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0 2569    7  934  442  544 1559 2814  324 1170   51  990  605 4125\n",
            " 9359 6041 3255   17]\n"
          ]
        }
      ],
      "source": [
        "n=200 # You can adjust n\n",
        "print('Shape: ',X_train_seq.shape)\n",
        "print(100*'-')\n",
        "print('Example: ',X_train_seq[n,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "up5z6eIoALF8",
        "outputId": "9ad46d21-4e15-4c97-ecfc-d5b6810f69e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "w2v = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSnC-jumALJD",
        "outputId": "6668f9f8-aafa-4c1e-c889-16c69f93321f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v['hello'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "mgCYBOx4ALK3"
      },
      "outputs": [],
      "source": [
        "emb_matrix=np.zeros((max_words+1, 300))\n",
        "for i in range(max_words):\n",
        "    w = reverse_voc[i+1]\n",
        "    if w in w2v:\n",
        "        emb_matrix[i+1,:] = w2v[w]\n",
        "emb_size = emb_matrix.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BRNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vrUaBm6aALNi"
      },
      "outputs": [],
      "source": [
        "def brnnModel():\n",
        "  input_ = layers.Input(shape=X_train_seq.shape[1:], name='input')\n",
        "  x = layers.Embedding(max_words + 1, emb_size, weights=[emb_matrix], trainable=False, name='embedding')(input_)\n",
        "  x = layers.Bidirectional(layers.SimpleRNN(15, dropout=0.2, return_sequences=False), name='bidirectional-rnn')(x)  # BRNN layer\n",
        "  x = layers.Dropout(0.2, name='dropout')(x)\n",
        "  x = layers.Dense(64, activation='relu', name='dense')(x)\n",
        "  output = layers.Dense(nr_categories, activation='softmax', name='classification')(x)\n",
        "  callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, verbose=1),  # Stop training if validation loss does not improve for 3 epochs\n",
        "    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)  # Save the best model based on validation accuracy\n",
        "  ]\n",
        "\n",
        "  # Create the model\n",
        "  model = models.Model(input_, output)\n",
        "  return model,callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "83BpGNUfATb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-13 09:01:08.092183: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-02-13 09:01:08.248512: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "brnn_model,callbacks=brnnModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "brnn_model2,callbacks=brnnModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ho9a1xIpATeq"
      },
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9)\n",
        "brnn_model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9)\n",
        "brnn_model2.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWh_0u_CAThX",
        "outputId": "41dd687e-6446-4bf9-d09c-364a7d9b4786"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 200, 300)          6000300   \n",
            "                                                                 \n",
            " bidirectional-rnn (Bidirec  (None, 30)                9480      \n",
            " tional)                                                         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                1984      \n",
            "                                                                 \n",
            " classification (Dense)      (None, 4)                 260       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6012024 (22.93 MB)\n",
            "Trainable params: 11724 (45.80 KB)\n",
            "Non-trainable params: 6000300 (22.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "brnn_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltS7IFUDAZE1",
        "outputId": "d782894f-af44-41d9-beb0-689d7e9919b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7377 - accuracy: 0.7296\n",
            "Epoch 1: val_accuracy improved from -inf to 0.68776, saving model to best_model.h5\n",
            "938/938 [==============================] - 164s 175ms/step - loss: 0.7377 - accuracy: 0.7296 - val_loss: 0.7834 - val_accuracy: 0.6878\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yuvraj/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.7358\n",
            "Epoch 2: val_accuracy improved from 0.68776 to 0.77408, saving model to best_model.h5\n",
            "938/938 [==============================] - 143s 152ms/step - loss: 0.7378 - accuracy: 0.7358 - val_loss: 0.6704 - val_accuracy: 0.7741\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7579 - accuracy: 0.7291\n",
            "Epoch 3: val_accuracy did not improve from 0.77408\n",
            "938/938 [==============================] - 157s 167ms/step - loss: 0.7579 - accuracy: 0.7291 - val_loss: 0.6656 - val_accuracy: 0.7713\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.8885 - accuracy: 0.6326\n",
            "Epoch 4: val_accuracy did not improve from 0.77408\n",
            "938/938 [==============================] - 145s 155ms/step - loss: 0.8885 - accuracy: 0.6326 - val_loss: 1.1121 - val_accuracy: 0.5167\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.0977 - accuracy: 0.5198\n",
            "Epoch 5: val_accuracy did not improve from 0.77408\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 1.0977 - accuracy: 0.5198 - val_loss: 1.0235 - val_accuracy: 0.5568\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 1.0534 - accuracy: 0.5523\n",
            "Epoch 6: val_accuracy did not improve from 0.77408\n",
            "938/938 [==============================] - 159s 170ms/step - loss: 1.0534 - accuracy: 0.5523 - val_loss: 0.9614 - val_accuracy: 0.6118\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "history = brnn_model.fit(X_train_seq, y_train, batch_size=batch_size, shuffle=True, epochs=epoch,validation_data=(X_test_seq, y_test),callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7381 - accuracy: 0.7308\n",
            "Epoch 1: val_accuracy improved from -inf to 0.75224, saving model to best_model.h5\n",
            "938/938 [==============================] - 151s 159ms/step - loss: 0.7381 - accuracy: 0.7308 - val_loss: 0.7358 - val_accuracy: 0.7522\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yuvraj/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - ETA: 0s - loss: 0.7222 - accuracy: 0.7586\n",
            "Epoch 2: val_accuracy improved from 0.75224 to 0.76803, saving model to best_model.h5\n",
            "938/938 [==============================] - 155s 165ms/step - loss: 0.7222 - accuracy: 0.7586 - val_loss: 0.6714 - val_accuracy: 0.7680\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7833 - accuracy: 0.6814\n",
            "Epoch 3: val_accuracy did not improve from 0.76803\n",
            "938/938 [==============================] - 156s 166ms/step - loss: 0.7833 - accuracy: 0.6814 - val_loss: 0.7869 - val_accuracy: 0.6792\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.6794\n",
            "Epoch 4: val_accuracy did not improve from 0.76803\n",
            "938/938 [==============================] - 158s 168ms/step - loss: 0.7944 - accuracy: 0.6794 - val_loss: 0.7961 - val_accuracy: 0.6768\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.7321\n",
            "Epoch 5: val_accuracy improved from 0.76803 to 0.78592, saving model to best_model.h5\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.7221 - accuracy: 0.7321 - val_loss: 0.6277 - val_accuracy: 0.7859\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7159 - accuracy: 0.7353\n",
            "Epoch 6: val_accuracy did not improve from 0.78592\n",
            "938/938 [==============================] - 160s 170ms/step - loss: 0.7159 - accuracy: 0.7353 - val_loss: 0.6687 - val_accuracy: 0.7541\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.6617 - accuracy: 0.7735\n",
            "Epoch 7: val_accuracy improved from 0.78592 to 0.80118, saving model to best_model.h5\n",
            "938/938 [==============================] - 160s 171ms/step - loss: 0.6617 - accuracy: 0.7735 - val_loss: 0.5924 - val_accuracy: 0.8012\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7249 - accuracy: 0.7451\n",
            "Epoch 8: val_accuracy did not improve from 0.80118\n",
            "938/938 [==============================] - 160s 171ms/step - loss: 0.7249 - accuracy: 0.7451 - val_loss: 0.6708 - val_accuracy: 0.7764\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7319 - accuracy: 0.7355\n",
            "Epoch 9: val_accuracy did not improve from 0.80118\n",
            "938/938 [==============================] - 161s 171ms/step - loss: 0.7319 - accuracy: 0.7355 - val_loss: 0.6522 - val_accuracy: 0.7870\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.7459\n",
            "Epoch 10: val_accuracy did not improve from 0.80118\n",
            "938/938 [==============================] - 159s 169ms/step - loss: 0.7015 - accuracy: 0.7459 - val_loss: 0.6595 - val_accuracy: 0.7588\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ],
      "source": [
        "history2 = brnn_model2.fit(X_train_seq, y_train, batch_size=batch_size, shuffle=True, epochs=epoch,validation_data=(X_test_seq, y_test),callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "U2FgOg6Jd7EU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDVavDOUd7Gs",
        "outputId": "aafc7ea3-c691-4442-8fd4-dd2b1515ec27"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading punkt: <urlopen error [Errno -3] Temporary\n",
            "[nltk_data]     failure in name resolution>\n",
            "[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n",
            "[nltk_data]     Temporary failure in name resolution>\n",
            "[nltk_data] Error loading wordnet: <urlopen error [Errno -3] Temporary\n",
            "[nltk_data]     failure in name resolution>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "v-HdL180d7Jk"
      },
      "outputs": [],
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "vrt5PgfKeF1S"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text=str(text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens[0]=tokens[0][2:]\n",
        "    cleaned_text=[lemmatizer.lemmatize(word.lower()) for word in tokens if word.lower() not in stopwords and word not in string.punctuation]\n",
        "    return ' '.join(cleaned_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "yvabL7n1c7B7"
      },
      "outputs": [],
      "source": [
        "def predict(text):\n",
        "  cleaned_text=clean_text(text)\n",
        "  seq=tokenizer.texts_to_sequences(cleaned_text)\n",
        "  seq=kprocessing.sequence.pad_sequences(seq, maxlen=max_len)\n",
        "  pred_seq=np.expand_dims(seq,axis=1)\n",
        "  prediction=brnn_model.predict(seq)\n",
        "  print(prediction.shape)\n",
        "  prediction_per_sent=np.argmax(prediction,axis=1)\n",
        "  predicted_label=class_names[np.bincount(prediction_per_sent).argmax()]\n",
        "  print(predicted_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfk0JUH5fD5T",
        "outputId": "67edb9a1-1c1c-4179-f129-ca0ede4c25e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22/22 [==============================] - 0s 15ms/step\n",
            "(678, 4)\n",
            "Sci/Tech\n"
          ]
        }
      ],
      "source": [
        "predict(\"In recent years, artificial intelligence (AI) has revolutionized various industries, ranging from healthcare to finance. One of the most notable advancements in AI is the development of deep learning algorithms, which enable machines to learn complex patterns and make intelligent decisions autonomously. Applications of deep learning span diverse domains, including natural language processing (NLP), computer vision, and speech recognition. Companies are leveraging deep learning models to enhance customer experience, optimize business processes, and drive innovation. As the field continues to evolve, researchers are exploring novel architectures and techniques to push the boundaries of AI further. With the rapid advancements in technology and the growing availability of data, the potential for AI to reshape industries and improve human lives is more promising than ever.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "VsLKCe4EfFal"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "(8, 4)\n",
            "Sports\n"
          ]
        }
      ],
      "source": [
        "predict(\"down trend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lstmModel():\n",
        "  input_ = layers.Input(shape=X_train_seq.shape[1:], name='input')\n",
        "  x = layers.Embedding(max_words + 1, emb_size, weights=[emb_matrix], trainable=False, name='embedding')(input_)\n",
        "  x = layers.Bidirectional(layers.LSTM(15, dropout=0.2, return_sequences=False), name='bidirectional-rnn')(x)  # BRNN layer\n",
        "  x = layers.Dropout(0.2, name='dropout')(x)\n",
        "  x = layers.Dense(64, activation='relu', name='dense')(x)\n",
        "  output = layers.Dense(nr_categories, activation='softmax', name='classification')(x)\n",
        "  callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, verbose=1),  # Stop training if validation loss does not improve for 3 epochs\n",
        "    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)  # Save the best model based on validation accuracy\n",
        "  ]\n",
        "\n",
        "  # Create the model\n",
        "  model = models.Model(input_, output)\n",
        "  return model,callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "lstm_model,callbacks1=lstmModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.9)\n",
        "lstm_model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.3768 - accuracy: 0.8736\n",
            "Epoch 1: val_accuracy improved from 0.80118 to 0.89447, saving model to best_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yuvraj/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 228s 239ms/step - loss: 0.3768 - accuracy: 0.8736 - val_loss: 0.3115 - val_accuracy: 0.8945\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.3178 - accuracy: 0.8933\n",
            "Epoch 2: val_accuracy improved from 0.89447 to 0.89842, saving model to best_model.h5\n",
            "938/938 [==============================] - 243s 259ms/step - loss: 0.3178 - accuracy: 0.8933 - val_loss: 0.3042 - val_accuracy: 0.8984\n",
            "Epoch 3/10\n",
            " 59/938 [>.............................] - ETA: 3:45 - loss: 0.3031 - accuracy: 0.8987"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[107], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history3 \u001b[38;5;241m=\u001b[39m \u001b[43mlstm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test_seq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
            "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history_lstm = lstm_model.fit(X_train_seq, y_train, batch_size=batch_size, shuffle=True, epochs=epoch,validation_data=(X_test_seq, y_test),callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
